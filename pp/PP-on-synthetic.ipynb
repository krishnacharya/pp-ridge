{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MayjuI8twv0v"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gSVokXgrwovZ"
   },
   "outputs": [],
   "source": [
    "def weighted_rls_solution(weights:np.ndarray, X: np.ndarray, y:np.ndarray, lamb:float = 1.0) -> np.ndarray:\n",
    "  \"\"\"\n",
    "    Inputs\n",
    "      weights: one for each datapoint, shape (n,1) or (n,)\n",
    "      X: design matrix shape (n, d)\n",
    "      y: yvalues shape (n,1) or (n,)\n",
    "      lamb: L2 regularization parameter, default 1.0\n",
    "    Returns\n",
    "      dx1 solution theta\n",
    "  \"\"\"\n",
    "  n, d = X.shape\n",
    "  weights = weights.reshape(n,-1)\n",
    "  X_w = X * (weights**0.5)\n",
    "  y_w = y.reshape(n, -1) * (weights**0.5)\n",
    "  return np.linalg.solve(lamb * np.identity(d) + X_w.T @ X_w, X_w.T @ y_w)\n",
    "\n",
    "def evaluate_weighted_rls_objective(theta: np.ndarray, weights:np.ndarray, X: np.ndarray, y:np.ndarray, lamb:float = 1.0) -> float:\n",
    "  \"\"\"\n",
    "    Inputs\n",
    "      theta: candidate vector for which we want to evaluate the objective value, shape (d, 1) or (d,)\n",
    "      weights: one for each datapoint, shape (n,1) or (n,)\n",
    "      X: design matrix shape (n, d)\n",
    "      y: yvalues shape (n,1) or (n,)\n",
    "      lamb: L2 regularization parameter, default 1.0\n",
    "    Note: If you want to evaluate the objective on equal weighted rls objective just pass weights as 1/n...1/n\n",
    "  \"\"\"\n",
    "  n, d = X.shape\n",
    "  theta = theta.reshape(d, -1) # now shape (d, 1)\n",
    "  weights = weights.reshape(n, -1) #now shape (n, 1)\n",
    "  X_w = X * (weights**0.5) # shape (n, d)\n",
    "  y_w = y.reshape(n, -1) * (weights**0.5) # shape (n, 1)\n",
    "  return np.sum((X_w @ theta - y_w)**2) + lamb * np.linalg.norm(theta)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzzU_oG2xAqN"
   },
   "source": [
    "SAMPLING from L2 Laplace i.e. $p(x) \\propto exp(-\\beta ||x||_2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1UoHprVrxDUt"
   },
   "outputs": [],
   "source": [
    "def sample_l2lap(beta:float, d:int) -> np.array:\n",
    "  \"\"\"\n",
    "    Returns\n",
    "      d dimensional noise sampled from `L2 laplace'\n",
    "      https://math.stackexchange.com/questions/3801271/sampling-from-a-exponentiated-multivariate-distribution-with-l2-norm\n",
    "  \"\"\"\n",
    "  R = np.random.gamma(d, scale = 1.0/beta)\n",
    "  Z = np.random.normal(0, 1, size = d)\n",
    "  return R * (Z / np.linalg.norm(Z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aW7m3EYxvGS"
   },
   "source": [
    "Compute the beta used in L2 Laplace noise, this is then used to add central noise to the minimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3-iYrmknxroD"
   },
   "outputs": [],
   "source": [
    "def compute_beta(lamb, tot_epsilon):\n",
    "  '''\n",
    "    lamb: regularization parameter for ridge\n",
    "    tot_epsilon: sum of all the agents privacy requirements \\sum_i \\varepsilon_i]\n",
    "    Returns\n",
    "      beta used for L2 laplace central noise\n",
    "  '''\n",
    "  return (lamb/2) * (lamb**0.5 / (1 + lamb**0.5)) * tot_epsilon\n",
    "\n",
    "def compute_private_estimator(minimizer, beta, d):\n",
    "  '''\n",
    "    Private estimate after adding L2 laplace noise, note beta is calculated using epsilon required by each agent\n",
    "  '''\n",
    "  return minimizer + sample_l2lap(beta, d).reshape(d, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWDG9-xGxKY6"
   },
   "source": [
    "NORMAL DIST -- SYNTHETIC DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9gsDpwo3xH9G"
   },
   "outputs": [],
   "source": [
    "def generate_linear_data(n:int, theta:np.array, sigma:float):\n",
    "  '''\n",
    "    Input:\n",
    "      n: number of datapoints\n",
    "      theta: the true theta used to generate the data, shape (d,), one dimensional array\n",
    "      sigma: std for gaussian noise for the synthetic linear data\n",
    "    returns\n",
    "      X the design matrix shape is (n x d)\n",
    "      y the associated labels shape is (n,)\n",
    "  '''\n",
    "  X = np.random.rand(n, len(theta))\n",
    "  y = X @ theta + np.random.normal(0, sigma, size=n)\n",
    "  return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgSZtbwJy8VO"
   },
   "source": [
    "Generating the synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d1uQKD7Ay7yf"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize, minmax_scale\n",
    "\n",
    "n = 100 #number of datapoints\n",
    "theta = np.random.uniform(0, 10, size=10) # 3 dimensional\n",
    "d = len(theta)\n",
    "lamb = 1.0 # norm penalizer for ridge\n",
    "X, y = generate_linear_data(n=n, theta=theta, sigma=0.1)\n",
    "\n",
    "# Our theory is for all features within the L2 unit ball, and y's in [0,1]\n",
    "X = normalize(X, norm='l2') # each row is L2 normalized\n",
    "y = minmax_scale(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GtOt6Pi7zDEe"
   },
   "outputs": [],
   "source": [
    "# epsilons = np.random.uniform(1, 10, size=n) # epsilon required by each agent\n",
    "epsilons = np.array([0.1]*(n//2) + [1]*(n//2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-ObrbcwxoKg"
   },
   "source": [
    "### PERSONALIZED PRIVACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WagHK29kxPXD",
    "outputId": "deadcd31-5348-4e75-e476-19e3bf40fe31"
   },
   "outputs": [],
   "source": [
    "tot_epsilon = np.sum(epsilons)\n",
    "weights_pp = epsilons/tot_epsilon # weights used in the ridge regression for personalized privacy\n",
    "\n",
    "sol_exact_ridge_pp = weighted_rls_solution(weights_pp, X, y, lamb)\n",
    "print(\"pluggin exact soln back into weighted ridge\", evaluate_weighted_rls_objective(sol_exact_ridge_pp, weights_pp, X, y, lamb))\n",
    "beta_pp = compute_beta(lamb, tot_epsilon)\n",
    "print(\"beta for pp\", beta_pp)\n",
    "# to loop the part below\n",
    "runs = 1000\n",
    "unweighted_erm = []\n",
    "weighted_erm = []\n",
    "for _ in range(runs):\n",
    "  theta_hat_pp = compute_private_estimator(sol_exact_ridge_pp, beta_pp , d)\n",
    "  unweighted_erm.append(evaluate_weighted_rls_objective(theta_hat_pp, np.ones(n)/n, X, y, lamb))\n",
    "  weighted_erm.append(evaluate_weighted_rls_objective(theta_hat_pp, weights_pp, X, y, lamb))\n",
    "print(\"unweighted_erm_using_privateestimator\", np.mean(unweighted_erm), np.std(unweighted_erm)) # WE care about low values here!\n",
    "print(\"weighted_erm_using_privateestimator\", np.mean(weighted_erm), np.std(weighted_erm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CHBDXUwkywue"
   },
   "source": [
    "### *Not* PERSONALIZED PRIVACY\n",
    "\n",
    "  epsilon for all agents set to min of epsilons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p6NB2PeTxccZ",
    "outputId": "18019a39-8dc0-4de1-c43c-b8df95b1e3fc"
   },
   "outputs": [],
   "source": [
    "tot_epsilon = min(epsilons) * n\n",
    "weights_npp = np.ones(n) / n\n",
    "\n",
    "sol_exact_ridge_npp = weighted_rls_solution(weights_npp, X, y, lamb)\n",
    "print(\"pluggin exact soln back into unweighted ridge\", evaluate_weighted_rls_objective(sol_exact_ridge_npp, weights_npp, X, y, lamb))\n",
    "beta_npp = compute_beta(lamb, tot_epsilon)\n",
    "print(\"beta for not\",beta_npp)\n",
    "# to loop the part below\n",
    "runs = 1000\n",
    "unweighted_erm = []\n",
    "weighted_erm = []\n",
    "for _ in range(runs):\n",
    "  theta_hat_npp = compute_private_estimator(sol_exact_ridge_npp, beta_npp , d)\n",
    "  unweighted_erm.append(evaluate_weighted_rls_objective(theta_hat_npp, np.ones(n)/n, X, y, lamb))\n",
    "  weighted_erm.append(evaluate_weighted_rls_objective(theta_hat_npp, weights_npp, X, y, lamb))\n",
    "print(\"unweighted_erm_using_privateestimator\", np.mean(unweighted_erm), np.std(unweighted_erm)) # WE care about low values here!\n",
    "print(\"weighted_erm_using_privateestimator\", np.mean(weighted_erm), np.std(weighted_erm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INSURANCE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize, minmax_scale\n",
    "\n",
    "def one_hot(df, cols): # idk if sklearns one-hot encoder is similar\n",
    "    \"\"\"\n",
    "    df: pandas DataFrame\n",
    "    param: cols a list of columns to encode \n",
    "    return a DataFrame with one-hot encoding\n",
    "    \"\"\"\n",
    "    for each in cols:\n",
    "        dummies = pd.get_dummies(df[each], prefix=each, drop_first=False)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "    return df\n",
    "def numeric_scaler(df, cols):\n",
    "    '''\n",
    "    df: pandas dataframe\n",
    "    numeric_cols: (array of strings) column names for numeric variables\n",
    "\n",
    "    no return: does inplace operation\n",
    "    '''\n",
    "    df_new = df.copy()\n",
    "    mmscaler = MinMaxScaler()\n",
    "    df_new[cols] = mmscaler.fit_transform(df_new[cols])\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_medical = pd.read_csv('insurance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_medical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_all = ['age', 'bmi', 'children', 'charges']\n",
    "cat_all = ['sex', 'smoker', 'region']\n",
    "\n",
    "df_medical_mm = numeric_scaler(df_medical, numeric_all)\n",
    "df_medical_mm_oh = one_hot(df_medical_mm, cat_all)\n",
    "df_medical_mm_oh.drop(cat_all, axis = 1, inplace=True) # drop the categorics that were used to one hot encode\n",
    "df_medical_mm_oh = df_medical_mm_oh * 1.0 # make bool true, false into 1.0, 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_medical_mm_oh.drop('charges', axis=1).to_numpy()\n",
    "y = df_medical_mm_oh['charges'].to_numpy()\n",
    "X = normalize(X, norm='l2') # each row is L2 normalized\n",
    "# y = minmax_scale(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, d = X.shape\n",
    "lamb = 1.0\n",
    "epsilons = np.array([0.1]*(n//2) + [1]*(n//2)) # has to be even"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Personalized privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pluggin exact soln back into weighted ridge 0.06143817955856497\n",
      "beta for pp 183.975\n",
      "unweighted_erm_using_privateestimator 0.06647168255692947 0.002625592123434555\n",
      "weighted_erm_using_privateestimator 0.06565153591387154 0.002621507342250632\n"
     ]
    }
   ],
   "source": [
    "tot_epsilon = np.sum(epsilons)\n",
    "weights_pp = epsilons/tot_epsilon # weights used in the ridge regression for personalized privacy\n",
    "\n",
    "sol_exact_ridge_pp = weighted_rls_solution(weights_pp, X, y, lamb)\n",
    "print(\"pluggin exact soln back into weighted ridge\", evaluate_weighted_rls_objective(sol_exact_ridge_pp, weights_pp, X, y, lamb))\n",
    "beta_pp = compute_beta(lamb, tot_epsilon)\n",
    "print(\"beta for pp\", beta_pp)\n",
    "# to loop the part below\n",
    "runs = 1000\n",
    "unweighted_erm = []\n",
    "weighted_erm = []\n",
    "for _ in range(runs):\n",
    "  theta_hat_pp = compute_private_estimator(sol_exact_ridge_pp, beta_pp , d)\n",
    "  unweighted_erm.append(evaluate_weighted_rls_objective(theta_hat_pp, np.ones(n)/n, X, y, lamb))\n",
    "  weighted_erm.append(evaluate_weighted_rls_objective(theta_hat_pp, weights_pp, X, y, lamb))\n",
    "print(\"unweighted_erm_using_privateestimator\", np.mean(unweighted_erm), np.std(unweighted_erm)) # WE care about low values here!\n",
    "print(\"weighted_erm_using_privateestimator\", np.mean(weighted_erm), np.std(weighted_erm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not personalized privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pluggin exact soln back into unweighted ridge 0.06224927666537697\n",
      "beta for not 33.45\n",
      "unweighted_erm_using_privateestimator 0.18742785953975424 0.07416783950719678\n",
      "weighted_erm_using_privateestimator 0.18742785953975424 0.07416783950719678\n"
     ]
    }
   ],
   "source": [
    "tot_epsilon = min(epsilons) * n\n",
    "weights_npp = np.ones(n) / n\n",
    "\n",
    "sol_exact_ridge_npp = weighted_rls_solution(weights_npp, X, y, lamb)\n",
    "print(\"pluggin exact soln back into unweighted ridge\", evaluate_weighted_rls_objective(sol_exact_ridge_npp, weights_npp, X, y, lamb))\n",
    "beta_npp = compute_beta(lamb, tot_epsilon)\n",
    "print(\"beta for not\",beta_npp)\n",
    "# to loop the part below\n",
    "runs = 1000\n",
    "unweighted_erm = []\n",
    "weighted_erm = []\n",
    "for _ in range(runs):\n",
    "  theta_hat_npp = compute_private_estimator(sol_exact_ridge_npp, beta_npp , d)\n",
    "  unweighted_erm.append(evaluate_weighted_rls_objective(theta_hat_npp, np.ones(n)/n, X, y, lamb))\n",
    "  weighted_erm.append(evaluate_weighted_rls_objective(theta_hat_npp, weights_npp, X, y, lamb))\n",
    "print(\"unweighted_erm_using_privateestimator\", np.mean(unweighted_erm), np.std(unweighted_erm)) # WE care about low values here!\n",
    "print(\"weighted_erm_using_privateestimator\", np.mean(weighted_erm), np.std(weighted_erm))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "local_multigroup",
   "language": "python",
   "name": "local_multigroup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
